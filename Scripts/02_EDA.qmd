---
title: "EDA"
format: html
editor: 
  markdown: 
    wrap: 72
---

## Setup

```{r}
#| output: false

library(data.table)
library(tidyverse)
library(magrittr)

library(here) # avoid having to change between . and .. when running interactively vs knitting
library(DataExplorer)
library(tidymodels)
library(vip)
library(gridExtra)
```

```{r load_data}
#| cache: true

load(here("Output/01_output.RData"))
```

Use only training data for the EDA and set switch determining whether to do EDA for original or synthetic data. 

```{r}
switch_original <- FALSE

if (switch_original) {
  
  df_train <- output_01$df_train_org
  
} else {
  
  df_train <- training(output_01$data_split)
  
}
```

```{r}
summary(df_train)
```

A very straight forward data set. Fortunately, no missing values.

## Marginal Distributions

```{r}
df_train %>%
  select(!id) %>% 
  plot_histogram(ncol = 2)
```

```{r}
df_train %>% 
  select(!c(id, original)) %>% 
  plot_bar(ncol = 2)
```


Take aways: 

* Non of the continous distributions has a very skewed distribution, so transformations are probably not needed. 
* No severe class imbalance

### Distributions by target

```{r}
df_train %>% 
  select(!id) %>% 
  plot_boxplot(
    "target", 
    ncol = 3
  )
```


Take aways:

* urea and osmo looks fairly similar, as do gravity and cond

## Correlation

```{r}
df_train %>% 
  select(!c(id, original)) %>% 
  plot_correlation(type = "continuous")
```

Urea and osmo are fairly correlated and have similar marginal relationships with the target 

## Variable importance

### Only main effects

```{r}
rerun_main <- FALSE # In this case, the models runs extremely fast because the dataset is so small, however, this is best practice

if (rerun_main) {
  rf_fit_main <-
    rand_forest() %>%
    set_mode("classification") %>%
    set_engine(
      "ranger",
      importance = "impurity"
    ) %>%
    fit(
      formula = target ~ .,
      data = df_train %>% select(!c(id, original))
    )
  
  rf_var_imp_main <- 
      rf_fit_main %>%
      vi()
  
  save( # caching does not really work for som reason
    rf_var_imp_main,
    file = here("Output/02_featImp_main.RData")
  )
  
}

```

```{r}
#| fig-height: 4

load(here("Output/02_featImp_main.RData"))

rf_var_imp_main %>%
  vip()

```


### With interaction features

```{r}
#| cache: true

# -- Include "brute force" interaction terms

rerun_int <- FALSE

if (rerun_int) {
  rf_rec_int <- 
    recipe(
      formula = target ~ .,
      data = df_train %>% select(!c(id, original))
    ) %>% 
    step_interact(
      terms = ~ all_predictors():all_predictors()
    )
  
  rf_spec_int <- 
    rand_forest() %>% 
    set_mode("classification") %>% 
    set_engine(
      "ranger",
      importance = "impurity"
    )
  
  rf_wflow_int <- 
    workflow() %>% 
    add_recipe(rf_rec_int) %>% 
    add_model(rf_spec_int)
  
  rf_fit_int <- 
    rf_wflow_int %>% 
    fit(df_train %>% select(!id))
  
  rf_var_imp <- 
      rf_fit_int %>%
      extract_fit_parsnip() %>% 
      vi()
  
  save(
    rf_var_imp,
    file = here("Output/02_featImp_int.RData")
  )
  
}

```

```{r}
#| cache: true
#| fig-height: 11

load(here("Output/02_featImp_int.RData"))

rf_var_imp %>%
  vip(num_features = 21)

```


# To do

* Acount for data scarcity
* Bin categorical features. Note in particular that there are 20 unique values of store_sqft, each of which denote a different store. We might want to encode this as a factor. 
* Normalize predictors
* Salad bar and prepared food is the same variable
* Try to include external data as well
